{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "import requests\n",
    "import stanfordnlp\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_MSMARCO_TRAIN = \"../../data/external/msmarco/train_v2.1.json\"\n",
    "PATH_MSMARCO_VALID = \"../../data/external/msmarco/dev_v2.1.json\"\n",
    "\n",
    "PATH_NLTK_RESOURCES = \"../../data/external/nltk/\"\n",
    "PATH_STANFORD_RESOURCES = \"../../data/external/stanfordnlp/\"\n",
    "\n",
    "PATH_SAVE_DATASET = \"../../data/question-answering/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     ../../data/downloads/nltk_data/...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt', PATH_NLTK_RESOURCES)\n",
    "nltk.data.path.append(PATH_NLTK_RESOURCES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the default treebank \"en_ewt\" for language \"en\".\n",
      "Use device: gpu\n",
      "\tTorch-GPU-ID: 0\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '../../data/downloads/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'pretokenized': True, 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '../../data/downloads/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '../../data/downloads/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "stanfordnlp.download('en', PATH_STANFORD_RESOURCES)\n",
    "stanford_nlp = stanfordnlp.Pipeline(processors='tokenize,pos',\n",
    "                                    tokenize_pretokenized=True,\n",
    "                                    models_dir=PATH_STANFORD_RESOURCES,\n",
    "                                    treebank='en_ewt', use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    # For reproducibility\n",
    "    # (https://pytorch.org/docs/stable/notes/randomness.html)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MSMARCO Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    json_file = open(path)\n",
    "    return json.load(json_file)\n",
    "\n",
    "\n",
    "def simple_format(dataset):\n",
    "    questions = {}\n",
    "    for key in dataset['query_id'].keys():\n",
    "        sample = {'question': dataset['query'][key].replace('?', ''),\n",
    "                  'answer': dataset['answers'][key],\n",
    "                  'type': dataset['query_type'][key]}\n",
    "        questions.update({key: sample})\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = simple_format(load_dataset(PATH_MSMARCO_TRAIN))\n",
    "valid = simple_format(load_dataset(PATH_MSMARCO_VALID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS MARCO size:\n",
      "\tTraining set: 808,731\n",
      "\tValidation set: 101,093\n"
     ]
    }
   ],
   "source": [
    "print(\"MS MARCO size:\")\n",
    "print(f\"\\tTraining set: {len(train):,}\")\n",
    "print(f\"\\tValidation set: {len(valid):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS-Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offset_of_tags_in_sentence(sentence, tags):\n",
    "    # go from left to right and determine tag offsets\n",
    "    offsets = []\n",
    "    total_offset = 0\n",
    "    for tag in tags:\n",
    "        label = tag[0]\n",
    "        local_offset = sentence.find(label)\n",
    "        offset = total_offset + local_offset\n",
    "        offsets.append(offset)\n",
    "\n",
    "        # prepare for next iteration\n",
    "        sentence = sentence[local_offset + len(label):]\n",
    "        total_offset = offset + len(label)\n",
    "    return offsets\n",
    "\n",
    "\n",
    "def get_pos_tags_of_sentence(sentence):\n",
    "    tags = []\n",
    "    for token in sentence.tokens:\n",
    "        for word in token.words:\n",
    "            tags.append((word.text, word.pos))\n",
    "    return tags\n",
    "\n",
    "\n",
    "def calculate_pos_tags_for_string(doc):\n",
    "    tags = []\n",
    "    for sentence in doc.sentences:\n",
    "        sentence_pos = []\n",
    "        for pos in get_pos_tags_of_sentence(sentence):\n",
    "            sentence_pos.append(pos)\n",
    "        tags.append(sentence_pos)\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagging(strings):\n",
    "    batch = '\\n\\n'.join([' '.join(word_tokenize(string))\n",
    "                         for string in strings])\n",
    "    doc = stanford_nlp(batch)\n",
    "    tags = calculate_pos_tags_for_string(doc)\n",
    "\n",
    "    assert len(tags) == len(strings)\n",
    "\n",
    "    result = []\n",
    "    for i in range(len(strings)):\n",
    "        offsets = get_offset_of_tags_in_sentence(strings[i], tags[i])\n",
    "        result.append([(tags[i][x][0], tags[i][x][1], str(offsets[x]))\n",
    "                       for x in range(len(tags[i]))])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sample(sample):\n",
    "    return not (sample['question'] is None\n",
    "                or len(sample['question'].strip()) == 0)\n",
    "\n",
    "\n",
    "def calculate_pos_tags(dataset):\n",
    "    strings = [sample['question'] for sample in dataset.values()\n",
    "               if clean_sample(sample)]\n",
    "    result = pos_tagging(strings)\n",
    "\n",
    "    i = 0\n",
    "    for sample in dataset.values():\n",
    "\n",
    "        if sample['question'] is None or len(sample['question'].strip()) == 0:\n",
    "            continue\n",
    "\n",
    "        sample['question:POS'] = result[i]\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_pos_tags(train)\n",
    "calculate_pos_tags(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_question_without_answer(sample):\n",
    "    if 'No Answer Present.' in sample['answer']:\n",
    "        return True\n",
    "\n",
    "    all_answers_are_empty = True\n",
    "    for answer in sample['answer']:\n",
    "        if not answer == '':\n",
    "            all_answers_are_empty = False\n",
    "    return all_answers_are_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_answers_match(regex, list_of_answers):\n",
    "    matches = True\n",
    "    for answer in list_of_answers:\n",
    "        if not re.match(regex, answer):\n",
    "            matches = False\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_is_yes(sample):\n",
    "    if is_question_without_answer(sample):\n",
    "        return False\n",
    "    all_answers = [s.lower() for s in sample['answer']]\n",
    "    return all_answers_match(\"^yes,?.*$\", all_answers)\n",
    "\n",
    "\n",
    "def answer_is_no(sample):\n",
    "    if is_question_without_answer(sample):\n",
    "        return False\n",
    "    all_answers = [s.lower() for s in sample['answer']]\n",
    "    return all_answers_match(r\"^(no$)|(no[,\\.].*$)|(no\\s.*$)\", all_answers)\n",
    "\n",
    "\n",
    "def is_binary(sample):\n",
    "    return answer_is_yes(sample) or answer_is_no(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagging(doc):\n",
    "    tags = []\n",
    "    for sentence in doc.sentences:\n",
    "        for pos in get_pos_tags_of_sentence(sentence):\n",
    "            tags.append(pos)\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalize(question_pattern, template):\n",
    "    question_pos_tags = pos_tagging(stanford_nlp(question_pattern))\n",
    "\n",
    "    regex_string = \"^\"\n",
    "    for question_pos in question_pos_tags:\n",
    "        if question_pos[0] == \"X\":\n",
    "            regex_string += \"(.*) \"\n",
    "        else:\n",
    "            regex_string += question_pos[0] + r\"/[^\\s]* \"\n",
    "\n",
    "    regex_string = regex_string[:-1] + \"$\"\n",
    "    regex = re.compile(regex_string)\n",
    "    return (question_pattern, regex, question_pos_tags, template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_question(question_pos_tags, pattern):\n",
    "    question_elements = [tag[0].replace(\"/\", \"_\").lower() + '/' + tag[1]\n",
    "                         for tag in question_pos_tags]\n",
    "    prepared_question = ' '.join(question_elements)\n",
    "    forbidden_pos = ['IN', 'CC', 'TO', 'WDT', 'WRB', 'WP']\n",
    "\n",
    "    match = pattern.search(prepared_question)\n",
    "\n",
    "    if match is None:\n",
    "        return False\n",
    "\n",
    "    for group in match.groups():\n",
    "        elements = group.split(\" \")\n",
    "        for element in elements:\n",
    "            token, pos = element.split('/')\n",
    "            if pos in forbidden_pos:\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Definitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASKING_FOR_RELATION_FORWARDS = 0\n",
    "ASKING_FOR_RELATION_BACKWARDS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_cause_patterns = []\n",
    "\n",
    "# Can-Questions\n",
    "may_cause_patterns.append(generalize(\n",
    "    \"can X cause X\", ASKING_FOR_RELATION_FORWARDS))\n",
    "may_cause_patterns.append(generalize(\n",
    "    \"can X be caused by X\", ASKING_FOR_RELATION_FORWARDS))\n",
    "\n",
    "# Do/Does-Questions\n",
    "may_cause_patterns.append(generalize(\n",
    "    \"do X cause X\", ASKING_FOR_RELATION_FORWARDS))\n",
    "may_cause_patterns.append(generalize(\n",
    "    \"does X cause X\", ASKING_FOR_RELATION_FORWARDS))\n",
    "may_cause_patterns.append(generalize(\n",
    "    \"did X cause X\", ASKING_FOR_RELATION_FORWARDS))\n",
    "\n",
    "# is questions\n",
    "may_cause_patterns.append(generalize(\n",
    "    \"is X caused by X\", ASKING_FOR_RELATION_BACKWARDS))\n",
    "may_cause_patterns.append(generalize(\n",
    "    \"are X caused by X\", ASKING_FOR_RELATION_BACKWARDS))\n",
    "may_cause_patterns.append(generalize(\n",
    "    \"is X causing X\", ASKING_FOR_RELATION_FORWARDS))\n",
    "may_cause_patterns.append(generalize(\n",
    "    \"is X a symptom of X\", ASKING_FOR_RELATION_BACKWARDS))\n",
    "may_cause_patterns.append(generalize(\n",
    "    \"is X a cause of X\", ASKING_FOR_RELATION_BACKWARDS))\n",
    "may_cause_patterns.append(generalize(\n",
    "    \"is X causes X\", ASKING_FOR_RELATION_BACKWARDS))\n",
    "may_cause_patterns.append(generalize(\n",
    "    \"is X caused from X\", ASKING_FOR_RELATION_BACKWARDS))\n",
    "may_cause_patterns.append(generalize(\n",
    "    \"is X cause for X\", ASKING_FOR_RELATION_BACKWARDS))\n",
    "\n",
    "# will questions\n",
    "may_cause_patterns.append(generalize(\n",
    "    \"will X cause X\", ASKING_FOR_RELATION_FORWARDS))\n",
    "\n",
    "# would could\n",
    "may_cause_patterns.append(generalize(\n",
    "    \"would X cause X\", ASKING_FOR_RELATION_FORWARDS))\n",
    "may_cause_patterns.append(generalize(\n",
    "    \"could X cause X\", ASKING_FOR_RELATION_FORWARDS))\n",
    "\n",
    "# others\n",
    "may_cause_patterns.append(generalize(\n",
    "    \"X caused by X\", ASKING_FOR_RELATION_BACKWARDS))\n",
    "may_cause_patterns.append(generalize(\n",
    "    \"X causes X\", ASKING_FOR_RELATION_BACKWARDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(may_cause_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_cause_patterns.sort(key=lambda x: len(x[0]), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_concept(question_pos, pattern):\n",
    "    pattern_tokens = [t[0] for t in pattern[2]]\n",
    "    pattern_tokens.remove('X')\n",
    "\n",
    "    tags = []\n",
    "    for i in range(len(question_pos)):\n",
    "        pos = question_pos[i]\n",
    "        pos_conditions = pos[1] in ['DT', 'PRP$'] and pos[0].lower() != 'no'\n",
    "\n",
    "        if pos[0].lower() in pattern_tokens:\n",
    "            tags.append(0)\n",
    "        elif (i == 0 or tags[i-1] == 0) and pos_conditions:\n",
    "            tags.append(0)\n",
    "        else:\n",
    "            tags.append(1)\n",
    "\n",
    "    annotation = []\n",
    "    start = -1\n",
    "    for i in range(len(tags) + 1):\n",
    "\n",
    "        if i == len(tags) and start > -1:\n",
    "            annotation.append([start, i-1])\n",
    "            start = -1\n",
    "            continue\n",
    "\n",
    "        if i == len(tags):\n",
    "            break\n",
    "\n",
    "        if tags[i] == 0 and start > -1:\n",
    "            annotation.append([start, i-1])\n",
    "            start = -1\n",
    "            continue\n",
    "\n",
    "        if tags[i] == 1 and start == -1:\n",
    "            start = i\n",
    "            continue\n",
    "    return annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_causal_questions_by_regex(dataset):\n",
    "    result = {}\n",
    "\n",
    "    for key in dataset:\n",
    "        sample = dataset[key]\n",
    "\n",
    "        for pattern in may_cause_patterns:\n",
    "            if simple_question(sample['question:POS'], pattern[1]):\n",
    "                sample['template'] = pattern[3]\n",
    "                sample['concepts'] = extract_concept(\n",
    "                    sample['question:POS'], pattern)\n",
    "\n",
    "                if len(sample['concepts']) == 2:\n",
    "                    result.update({key: sample})\n",
    "                break\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_train = get_causal_questions_by_regex(train)\n",
    "questions_valid = get_causal_questions_by_regex(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3960\n",
      "489\n",
      "4449\n"
     ]
    }
   ],
   "source": [
    "print(len(questions_train))\n",
    "print(len(questions_valid))\n",
    "print(len(questions_train) + len(questions_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_queries(dataset):\n",
    "    for sample in dataset.values():\n",
    "        if sample['template'] == ASKING_FOR_RELATION_FORWARDS:\n",
    "            sample['query'] = (sample['concepts'][0], sample['concepts'][1])\n",
    "        elif sample['template'] == ASKING_FOR_RELATION_BACKWARDS:\n",
    "            sample['query'] = (sample['concepts'][1], sample['concepts'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_queries(questions_train)\n",
    "create_queries(questions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answers(dataset):\n",
    "\n",
    "    new_dataset = []\n",
    "\n",
    "    for sample in dataset.values():\n",
    "        sample['answer:Extracted'] = []\n",
    "\n",
    "        if answer_is_yes(sample):\n",
    "            sample['answer:Extracted'].append(\"Yes\")\n",
    "            new_dataset.append(sample)\n",
    "            continue\n",
    "\n",
    "        if answer_is_no(sample):\n",
    "            sample['answer:Extracted'].append(\"No\")\n",
    "            new_dataset.append(sample)\n",
    "            continue\n",
    "\n",
    "        if is_question_without_answer(sample):\n",
    "            sample['answer:Extracted'].append(\"No Answer Present.\")\n",
    "            new_dataset.append(sample)\n",
    "            continue\n",
    "\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_qa_dataset_train = extract_answers(questions_train)\n",
    "final_qa_dataset_valid = extract_answers(questions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2169\n"
     ]
    }
   ],
   "source": [
    "number_binary = 0\n",
    "for sample in final_qa_dataset_train + final_qa_dataset_valid:\n",
    "    if is_binary(sample):\n",
    "        number_binary += 1\n",
    "\n",
    "print(number_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4287"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_qa_dataset_train) + len(final_qa_dataset_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disambiguate(text):\n",
    "    url = 'http://localhost:2222/rest/disambiguate/'\n",
    "    headers = {'accept': 'application/json'}\n",
    "    payload = {'text': text, 'confidence': '0.4', 'support': \"0\"}\n",
    "    return requests.get(url, params=payload, headers=headers).json()\n",
    "\n",
    "\n",
    "def entity_linking(text, offset):\n",
    "    query = \"<annotation text=\\\"\" + text + \"\\\">\\n\"\n",
    "    query += \"\\t<surfaceForm name=\\\"\" + text\n",
    "    query += \"\\\" offset=\\\"\" + str(offset) + \"\\\" />\\n\"\n",
    "    query += \"</annotation>\"\n",
    "\n",
    "    result = disambiguate(query)\n",
    "    if result == \"\" or 'Resources' not in result.keys():\n",
    "        return None\n",
    "    return [r['@URI'] for r in result['Resources']][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query(sample, concept_range):\n",
    "    start = int(sample['question:POS'][concept_range[0]][2])\n",
    "    end = int(sample['question:POS'][concept_range[1]][2])\n",
    "    end += len(sample['question:POS'][concept_range[1]][0])\n",
    "    return sample['question'][start:end], start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Start dbpedia spotlight\n",
    "    (more instructions in README.md)\n",
    "\n",
    "    $ cd ../../data/downloads/dbpedia-spotlight/\n",
    "    $ java -jar -Xmx30G -Xms30G dbpedia-spotlight-1.0.0.jar en \\\n",
    "    http://localhost:2222/rest\n",
    "'''\n",
    "expected_entity = 'http://dbpedia.org/resource/Tobacco_smoking'\n",
    "assert entity_linking(\"Tobacco Smoking\", 0) == expected_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in final_qa_dataset_train + final_qa_dataset_valid:\n",
    "    cause_entity = entity_linking(*get_query(sample, sample['query'][0]))\n",
    "    effect_entity = entity_linking(*get_query(sample, sample['query'][1]))\n",
    "    sample['entities:dbo'] = [cause_entity, effect_entity]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(dataset, name):\n",
    "    jsonarray = json.dumps(dataset)\n",
    "    dataset_file = open(PATH_SAVE_DATASET + name, \"w+\")\n",
    "    dataset_file.write(jsonarray)\n",
    "    dataset_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(final_qa_dataset_train, \"causality-qa-training.json\")\n",
    "save(final_qa_dataset_valid, \"causality-qa-validation.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cikm20-causenet",
   "language": "python",
   "name": "cikm20-causenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "notify_time": "10",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
